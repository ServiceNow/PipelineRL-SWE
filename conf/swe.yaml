defaults:
  - base
  - override finetune: grpo
  - _self_

# Override the rollout policy for localization
actor:
  rollout_policy: pipelinerl.swe.rollouts.pipeline.generate_unified_swe_rollout
  log_each_n_secs: 10
  llm_max_rollouts: 64
  rollout_workers: 1
  discount_factor: 1
  task_template: "{task}"
  throughput_window_size: 50
  success_threshold: 0.8  # For repair stage

# Use SWE dataset loader
dataset_loader: pipelinerl.swe.load_datasets.load_local_swe_dataset
train_dataset_names:
  - swegym
test_dataset_names:
  - swebench_lite

# Agent-specific settings
agent:
  max_prompt_length: 48000
  selection_max_prompt_length: 48000
  repair_max_prompt_length: 48000
  # A2A agent settings
  query_generation_max_prompt_length: 16000
  expert_advice_max_prompt_length: 20000

# Finetune settings optimized for localization
finetune:
  seq_length: 48000  # Shorter sequences for query generation
  gradient_accumulation_passes: 512  # Adjust based on your setup
  rl:
    temperature: ${...llm.parameters.temperature}

# LLM settings for localization
llm:
  parameters:
    max_tokens: 2000  # Short outputs for search queries
    temperature: 1.0

test_llm:
  parameters:
    max_tokens: 2000
    temperature: 0.8  # Slightly lower for more focused queries during eval

# Environment is not needed for localization
environment: null

# SWE-specific dataset parameters
dataset_loader_params:
  dataset_path: /mnt/llmd/data/swegym/ds
  test_dataset_path: /mnt/llmd/data/swebench_lite/ds

# Model path - use a coding-focused model if available
model_path: Qwen/Qwen2.5-Coder-7B-Instruct

# Evaluation settings
eval_every_n_versions: 1000

swe:
  # Stage enablement flags
  enable_localization: true
  enable_file_selection: true
  enable_repair: true
  
  # Run flags (for stages that contribute to training data)
  run_localization: true
  run_file_selection: true
  run_repair: true
  
  # Self-evaluation flags (enable generic self-eval for each stage)
  enable_localization_self_eval: true
  enable_file_selection_self_eval: true
  enable_repair_self_eval: true
  
  # A2A system configuration
  enable_a2a: false
  
  # A2A trigger thresholds (when to consult expert model)
  localization_a2a_trigger_threshold: 0.5
  file_selection_a2a_trigger_threshold: 0.5  
  repair_a2a_trigger_threshold: 0.5
  
  # Expert model configuration (port 8280)
  expert_model:
    base_url: "http://localhost:8280"
    model_name: "Qwen/Qwen2.5-Coder-32B-Instruct"
    parameters:
      max_tokens: 64000
      temperature: 1.0
    timeout: 300  # seconds
    max_retries: 3
  
  # Repository paths
  repo_path_train: /mnt/llmd/data/swegym/repos
  repo_path_test: /mnt/llmd/data/swebench_lite/repos
  
  # Self-evaluation and repair settings
  enable_self_eval: true
  run_self_eval: true
  
  # Abstention threshold (config-fixed threshold for all stages)
  abstention_threshold: 0.5  # Examples with self-eval score < 0.5 will be marked for abstention

swe_preprocessor_args:
  repo_path: /mnt/llmd/data/swegym/repos
  dataset_path: /mnt/llmd/data/swegym/ds
  min_token_threshold: 10
  max_token_threshold: 5000
  num_map_processes: 32
  tokenizer_model: Qwen/Qwen2.5-Coder-7B-Instruct
  force_reprocess: false
  hf_dataset_name: SWE-Gym/SWE-Gym
  hf_split_name: train

world:
  expert_llm:
    enabled: false
    model_path: Qwen/Qwen2.5-Coder-32B-Instruct
    vllm_kwargs:
      max-model-len: 16000
      gpu_memory_utilization: 0.95