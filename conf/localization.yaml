defaults:
  - base
  - _self_

# Override the rollout policy for localization
actor:
  rollout_policy: pipelinerl.swe.localization_rollouts.generate_localization_rollout
  log_each_n_secs: 10
  llm_max_rollouts: 64
  rollout_workers: 1
  discount_factor: 1
  system_prompt: Please generate a search query to find files relevant to fixing this issue.
  task_template: "{task}"
  throughput_window_size: 50

# Use SWE dataset loader
dataset_loader: pipelinerl.swe.load_datasets.load_local_swe_dataset
train_dataset_names:
  - swegym
test_dataset_names:
  - swebench_lite

# Localization-specific settings
agent:
  max_prompt_length: 48000

# Finetune settings optimized for localization
finetune:
  seq_length: 50000  # Shorter sequences for query generation
  gradient_accumulation_passes: 512  # Adjust based on your setup
  learning_rate: 5e-6  # Slightly higher for localization learning
  rl:
    algo: reinforce  # Simple REINFORCE for localization
    use_advantages: true
    kl_coef: 0.0
    entropy_bonus: 0.0
    temperature: ${...llm.parameters.temperature}

# LLM settings for localization
llm:
  parameters:
    max_tokens: 2000  # Short outputs for search queries
    temperature: 1.0

test_llm:
  parameters:
    max_tokens: 2000
    temperature: 0.8  # Slightly lower for more focused queries during eval

# Environment is not needed for localization
environment: null

# SWE-specific dataset parameters
dataset_loader_params:
  dataset_path: /mnt/llmd/data/swegym/ds
  test_dataset_path: /mnt/llmd/data/swebench_lite/ds

# Model path - use a coding-focused model if available
model_path: Qwen/Qwen2.5-Coder-7B-Instruct

# Evaluation settings
eval_every_n_versions: 1000